# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

# Load dataset
data = pd.read_csv('Social_Network_Ads.csv')
X = data[['Age', 'EstimatedSalary']]
y = data['Purchased']

# Feature scaling
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

# Classifiers
models = {
    'Logistic Regression': LogisticRegression(),
    'KNN': KNeighborsClassifier(),
    'SVM': SVC(probability=True),
    'Decision Tree': DecisionTreeClassifier(),
    'Random Forest': RandomForestClassifier()
}

results = []
fitted_models = {}

# Train & evaluate models
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    fitted_models[name] = model

    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred)
    rec = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)

    results.append({
        'Model': name,
        'Accuracy': acc,
        'Precision': prec,
        'Recall': rec,
        'F1 Score': f1
    })

    print(f"\n{name} Classification Report:")
    print(classification_report(y_test, y_pred))

# Results DataFrame
results_df = pd.DataFrame(results)
print("\nModel Comparison:\n", results_df.sort_values(by='Accuracy', ascending=False))

# Plot Accuracy Comparison
plt.figure(figsize=(8, 5))
sns.barplot(data=results_df, x='Model', y='Accuracy', palette='coolwarm')
plt.title('Model Accuracy Comparison')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# Confusion Matrix for top model (Random Forest)
best_model = fitted_models['Random Forest']
ConfusionMatrixDisplay.from_estimator(best_model, X_test, y_test, cmap='Blues')
plt.title('Confusion Matrix - Random Forest')
plt.show()

# Graphical Predictions
test_cases = pd.DataFrame([
    [30, 87000], [40, 0], [40, 100000], [50, 0],
    [18, 0], [22, 600000], [35, 2500000], [60, 100000000]
], columns=['Age', 'EstimatedSalary'])

scaled_cases = scaler.transform(test_cases)
preds = best_model.predict(scaled_cases)

print("\nüìà Prediction Results:")
for (age, salary), pred in zip(test_cases.values, preds):
    status = "Likely to Purchase ‚úÖ" if pred == 1 else "Unlikely ‚ùå"
    print(f"Age {age}, Salary ‚Çπ{salary:,}: {status}")

# Hypothesis Simulation
ages = [20, 30, 40, 50, 60]
salaries = [0, 50000, 100000, 500000, 1000000]
sim_data = pd.DataFrame([(a, s) for a in ages for s in salaries], columns=['Age', 'EstimatedSalary'])
sim_scaled = scaler.transform(sim_data)
sim_data['Prediction'] = best_model.predict(sim_scaled)

# Plot Hypothesis Test
plt.figure(figsize=(10, 6))
sns.lineplot(data=sim_data, x='EstimatedSalary', y='Prediction', hue='Age', marker='o')
plt.title('Hypothesis: Salary vs Age Effect on Insurance Purchase')
plt.ylabel('Prediction (0=No, 1=Yes)')
plt.grid()
plt.tight_layout()
plt.show()
